# -*- coding: utf-8 -*-
"""作業29.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10IX9BR2KE-byJct3cpZh-JnEACubOd16
"""

# 切割訓練測試資料在用的 載入工具
from sklearn.model_selection import train_test_split

# 以下生成檢驗模型的工具 載入工具 
from sklearn.metrics import plot_confusion_matrix
from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix

import pandas as pd
import numpy as np
import datetime
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import tree
import pickle

current_time = datetime.datetime.now()
current = datetime.date.today()

## read in training data##
df = pd.read_csv('機台資料_標籤.csv',encoding="utf-8")
df['時間'] = pd.to_datetime(df['時間'])
df['裡面橫封溫度'] = df['裡面橫封溫度'].astype(str)
df['外面橫封溫度'] = df['外面橫封溫度'].astype(str)
df['橫封溫度設定'] = df['橫封溫度設定'].astype(str)
df['橫封溫度警報範圍'] = df['橫封溫度警報範圍'].astype(str)
df['豎封實際溫度'] = df['豎封實際溫度'].astype(str)
df['豎封溫度設定'] = df['豎封溫度設定'].astype(str)
df['打碼左邊實際溫度'] = df['打碼左邊實際溫度'].astype(str)
df['打碼右邊實際溫度'] = df['打碼右邊實際溫度'].astype(str)
df['標籤'] = df['標籤'].astype(str)

print(df.info())
print('空值數目', df.isnull().sum())
df = df.reset_index(drop=True)

# 把可能要用到的欄位抓進來(except 時間)#
Xdata = df[['裡面橫封溫度','外面橫封溫度','橫封溫度設定','橫封溫度警報範圍','豎封實際溫度','豎封溫度設定','打碼左邊實際溫度','打碼右邊實際溫度']]

# 標籤結果隔離出來
Ydata = df['標籤']

# 若擔心資料沒有平均抽出，可以使用sample喔
# 通常切割訓練測試資料是用train_test_split
# 兩種 x y 所有溫度跟標籤的關係 -> 切出訓練以及驗證資料 4:1, 3:!
X_train, X_test, y_train, y_test = train_test_split(Xdata, Ydata.values , test_size=0.2, random_state=20)

##read in prdiction data##

predict_data = pd.read_csv('機台預測資料.csv',encoding="utf-8")
predict_data['時間'] = pd.to_datetime(df['時間'])
predict_data['裡面橫封溫度'] = predict_data['裡面橫封溫度'].astype(str)
predict_data['外面橫封溫度'] = predict_data['外面橫封溫度'].astype(str)
predict_data['橫封溫度設定'] = predict_data['橫封溫度設定'].astype(str)
predict_data['橫封溫度警報範圍'] = predict_data['橫封溫度警報範圍'].astype(str)
predict_data['豎封實際溫度'] = predict_data['豎封實際溫度'].astype(str)
predict_data['豎封溫度設定'] = predict_data['豎封溫度設定'].astype(str)
predict_data['打碼左邊實際溫度'] = predict_data['打碼左邊實際溫度'].astype(str)
predict_data['打碼右邊實際溫度'] = predict_data['打碼右邊實際溫度'].astype(str)

predictX = predict_data[['裡面橫封溫度','外面橫封溫度','橫封溫度設定','橫封溫度警報範圍','豎封實際溫度','豎封溫度設定','打碼左邊實際溫度','打碼右邊實際溫度']]

##製作儲存指標的df##
evaluate = pd.DataFrame({
    'name': [],
    'accuracy': [],
    'test': [],
    'precision': [],
    'recall': [],
    'f1score': [],
})
evaluate

##製作函數for各項指標，輸出pkl跟cm##
def training(clf_name,clf,X_train,y_train):
  global evaluate
  clf.fit(X_train,y_train)
  print(f'algorithm is :{clf} ' + '\n')
  y_pred=clf.predict(X_test)
  accuracy_train=round(clf.score(X_train,y_train)*100,2)
  accuracy_test=round(clf.score(X_test,y_test)*100,2)
  precision=round(precision_score(y_test,y_pred,average='macro')*100,2)     
  recall=round(recall_score(y_test,y_pred,average='macro')*100,2)
  f1=round(f1_score(y_test,y_pred,average='macro')*100,2)
  result = pd.DataFrame({'name':[clf_name],'accuracy':[accuracy_train],'test':[accuracy_test],'precision':[precision],'recall':[recall],'f1score':[f1]})
  evaluate = pd.concat([evaluate,result],ignore_index=True)

  own = '/content/drive/MyDrive/作業29/train_detail/'
  detail = clf_name + '.pkl'
  location = own + detail 
  ##輸出模型檔##
  pickle.dump(clf, open(location,'wb'))

  ##進行預測並輸出結果##
  Y_pred = clf.predict(predictX)
  predict_result = pd.DataFrame(Y_pred)
  predict_result.rename( columns={0: '預測結果'}, inplace=True)
  predict_dataframe = pd.concat([predict_data,predict_result],axis=1)
  predict_dataframe.sort_values('時間', inplace=True, ascending=True)
  file_name = '機台預測結果.csv'
  location2 = own+file_name
  predict_dataframe.to_csv(location2,index=False)

  ##輸出confusion matrix##
  y_vaild = clf.predict(X_test)
  plot_name = clf_name + '_confusion_matrix.png'
  location3 = own + plot_name
  cm = confusion_matrix(y_test,y_vaild)
  cms = sns.heatmap(cm, square=True, annot=True, cbar=False, fmt='g')
  cms.set_title('demo_gnb_confusion_matrix')
  cms.set_xlabel("predicted value")
  cms.set_ylabel("true value")
  plt.rcParams['font.sans-serif']=['SimHei']
  plt.rcParams['axes.unicode_minus'] = False
  plt.savefig(location3,dpi=200)
  plt.show()
  plt.close()


  return np.array([[accuracy_train,accuracy_test,precision,recall,f1]])

"""#KNN"""

##KNN##
from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors = 3)
training('knn',knn,X_train,y_train)

"""#SVC"""

from sklearn.svm import LinearSVC

svc = LinearSVC()
training('svm',svc,X_train,y_train)

"""#SVM"""

from sklearn.svm import SVC

svm = SVC()
training('SVM',svm,X_train,y_train)

"""#Decision Tree"""

from sklearn.tree import DecisionTreeClassifier

dt3 = DecisionTreeClassifier(max_depth=3)
training('DT3',dt3,X_train,y_train)

dt4 = DecisionTreeClassifier(max_depth=4)
training('DT4',dt4,X_train,y_train)

dt5 = DecisionTreeClassifier(max_depth=5)
training('DT5',dt5,X_train,y_train)

"""#Logistic Regression"""

from sklearn import linear_model

lg = linear_model.LogisticRegression()
training('log',lg,X_train,y_train)

"""#GaussianNB"""

from sklearn.naive_bayes import GaussianNB

gaussNB = GaussianNB()
training('GaussianNB',gaussNB,X_train,y_train)

"""#MultinomialNB"""

from sklearn.naive_bayes import MultinomialNB

multiNB = MultinomialNB()
training('MultinomialNB',multiNB,X_train,y_train)

"""#Complement NB"""

from sklearn.naive_bayes import ComplementNB

compNB = ComplementNB()
training('ComplementNB',compNB,X_train,y_train)

"""#Categorical NB"""



from sklearn.naive_bayes import CategoricalNB

def training_cate(clf_name,clf,X_train,y_train):
  global evaluate
  clf.fit(X_train,y_train)
  print(f'algorithm is :{clf} ' + '\n')
  y_pred=clf.predict(X_test)
  accuracy_train=round(clf.score(X_train,y_train)*100,2)
  accuracy_test=round(clf.score(X_test,y_test)*100,2)
  precision=round(precision_score(y_test,y_pred,average='macro')*100,2)     
  recall=round(recall_score(y_test,y_pred,average='macro')*100,2)
  f1=round(f1_score(y_test,y_pred,average='macro')*100,2)
  result = pd.DataFrame({'name':[clf_name],'accuracy':[accuracy_train],'test':[accuracy_test],'precision':[precision],'recall':[recall],'f1score':[f1]})
  evaluate = pd.concat([evaluate,result],ignore_index=True)

  own = '/content/drive/MyDrive/作業29/train_detail/'
  detail = clf_name + '.pkl'
  location = own + detail 
  ##輸出模型檔##
  pickle.dump(clf, open(location,'wb'))

  ##進行預測並輸出結果##
  Y_pred = clf.predict(predictX)
  predict_result = pd.DataFrame(Y_pred)
  predict_result.rename( columns={0: '預測結果'}, inplace=True)
  predict_dataframe = pd.concat([predict_data,predict_result],axis=1)
  predict_dataframe.sort_values('時間', inplace=True, ascending=True)
  file_name = '機台預測結果.csv'
  location2 = own+file_name
  predict_dataframe.to_csv(location2,index=False)

  ##輸出confusion matrix##
  y_vaild = clf.predict(X_test[2:3])
  plot_name = clf_name + '_confusion_matrix.png'
  location3 = own + plot_name
  cm = confusion_matrix(y_test,y_vaild)
  cms = sns.heatmap(cm, square=True, annot=True, cbar=False, fmt='g')
  cms.set_title('demo_gnb_confusion_matrix')
  cms.set_xlabel("predicted value")
  cms.set_ylabel("true value")
  plt.rcParams['font.sans-serif']=['SimHei']
  plt.rcParams['axes.unicode_minus'] = False
  plt.savefig(location3,dpi=200)
  plt.show()
  plt.close()


  return np.array([[accuracy_train,accuracy_test,precision,recall,f1]])

cateNB = CategoricalNB(min_categories=2)
X_train, X_test, y_train, y_test = train_test_split(Xdata, Ydata.values , test_size=0.2,random_state=20)
training_cate('CategoricalNB',cateNB,X_train.astype('float'),y_train.astype('float'))

X_test.shape ##givp up

"""#BernoulliNB"""

from sklearn.naive_bayes import BernoulliNB

berNB = BernoulliNB()
training('BernoulliNB',berNB,X_train,y_train)

"""#Perceptron"""

from sklearn.linear_model import Perceptron

Percep = Perceptron()
training('Perceptron',Percep,X_train,y_train)

"""#Stochastic Gradient Descent"""

from sklearn.linear_model import SGDClassifier

sgd = SGDClassifier()
training('SGD',sgd,X_train,y_train)

"""#Bayesian Regression"""

##製作函數for各項指標，輸出pkl跟cm##
def training_bayes(clf_name,clf,X_train,y_train):
  global evaluate
  clf.fit(X_train,y_train)
  print(f'algorithm is :{clf} ' + '\n')
  y_pred=clf.predict(X_test)
  ##change prob to label##
  sd = y_pred.std()
  m = y_pred.mean()
  for i in range(len(y_pred)):
    if m+sd < y_pred[i] < m+sd*2:
      y_pred[i] = 1
    elif y_pred[i] > m+sd*2:
      y_pred[i] = 2
    else:
      y_pred[i] = 0
  
  y_pred = np.array(["%.0f" % w for w in y_pred.reshape(y_pred.size)])

  accuracy_train=round(clf.score(X_train,y_train)*100,2)
  accuracy_test=round(clf.score(X_test,y_test)*100,2)
  precision=round(precision_score(y_test,y_pred,average='macro')*100,2)     
  recall=round(recall_score(y_test,y_pred,average='macro')*100,2)
  f1=round(f1_score(y_test,y_pred,average='macro')*100,2)
  result = pd.DataFrame({'name':[clf_name],'accuracy':[accuracy_train],'test':[accuracy_test],'precision':[precision],'recall':[recall],'f1score':[f1]})
  evaluate = pd.concat([evaluate,result],ignore_index=True)

  own = '/content/drive/MyDrive/作業29/train_detail/'
  detail = clf_name + '.pkl'
  location = own + detail 
  ##輸出模型檔##
  # pickle.dump(clf, open(location,'wb'))

  ##進行預測並輸出結果##
  Y_pred = clf.predict(predictX)
  ##change prob to label##
  sd3,m3 = Y_pred.std(),Y_pred.mean()
  for i in range(len(Y_pred)):
    if m3+sd3 < Y_pred[i] < m3+sd3*2:
      Y_pred[i] = 1
    elif Y_pred[i] > m3+sd3*2:
      Y_pred[i] = 2
    else:
      Y_pred[i] = 0
  
  Y_pred = np.array(["%.0f" % w for w in Y_pred.reshape(Y_pred.size)])
  predict_result = pd.DataFrame(Y_pred)
  predict_result.rename( columns={0: '預測結果'}, inplace=True)
  predict_dataframe = pd.concat([predict_data,predict_result],axis=1)
  predict_dataframe.sort_values('時間', inplace=True, ascending=True)
  file_name = '機台預測結果.csv'
  location2 = own+file_name
  predict_dataframe.to_csv(location2,index=False)

  
  y_vaild = clf.predict(X_test)
  ##change prob to label##
  sd2,m2 = y_vaild.std(),y_vaild.mean()
  for i in range(len(y_vaild)):
    if m2+sd2 < y_vaild[i] < m2+sd2*2:
      y_vaild[i] = 1
    elif y_vaild[i] > m2+sd2*2:
      y_vaild[i] = 2
    else:
      y_vaild[i] = 0
  
  y_vaild = np.array(["%.0f" % w for w in y_vaild.reshape(y_vaild.size)])
  plot_name = clf_name + '_confusion_matrix.png'
  location3 = own + plot_name
  ##輸出confusion matrix##
  cm = confusion_matrix(y_test,y_vaild)
  cms = sns.heatmap(cm, square=True, annot=True, cbar=False, fmt='g')
  cms.set_title('demo_gnb_confusion_matrix')
  cms.set_xlabel("predicted value")
  cms.set_ylabel("true value")
  plt.rcParams['font.sans-serif']=['SimHei']
  plt.rcParams['axes.unicode_minus'] = False
  plt.savefig(location3,dpi=200)
  plt.show()
  plt.close()


  return np.array([[accuracy_train,accuracy_test,precision,recall,f1]])

from sklearn.linear_model import BayesianRidge

bayes = BayesianRidge()
training_bayes('BayesianRidge',bayes,X_train,y_train)

"""#Generalized Linear Regression"""

from sklearn.linear_model import LinearRegression

glm = LinearRegression()
training_bayes('glm',glm,X_train,y_train)

"""#Gaussian Process Regression """

from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel

kernel = DotProduct() + WhiteKernel()
gpr = GaussianProcessRegressor(kernel=kernel,random_state=0)
training_bayes('GPR',gpr,X_train,y_train)

##drop duplicates in evaluate then export##
evaluate.drop_duplicates(inplace=True)
evaluate.to_csv('/content/drive/MyDrive/作業29/train_detail/evaluate.csv')